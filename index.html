<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>PRE-EVAL</title>

  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Arial, sans-serif;
      background-color: #ffffff;
      color: #222;
      margin: 0;
      padding: 0;
    }

    .container {
      max-width: 900px;
      margin: 60px auto;
      padding: 0 20px;
      text-align: center;
    }

    h1 {
      font-size: 42px;
      font-weight: 600;
      margin-bottom: 20px;
    }

    .authors {
      font-size: 20px;
      margin-bottom: 14px;
    }

    .authors a {
      color: #1a73e8;
      text-decoration: none;
    }

    .authors a:hover {
      text-decoration: underline;
    }

    .affiliations {
  font-size: 18px;
  color: #555;
  max-width: 900px;
  margin: 0 auto 30px auto;
  line-height: 1.6;
}
.affiliation {
  display: inline;
  margin-right: 18px;
  white-space: normal;
}

    .buttons {
      margin: 30px 0;
    }

    .button {
      display: inline-block;
      margin: 6px;
      padding: 10px 18px;
      border-radius: 20px;
      background-color: #111;
      color: white;
      text-decoration: none;
      font-size: 15px;
    }

    .button:hover {
      background-color: #333;
    }

    .section {
      text-align: left;
      margin-top: 50px;
    }

    .section h2 {
      font-size: 26px;
      margin-bottom: 10px;
    }

    .section p {
      font-size: 17px;
      line-height: 1.6;
    }

      .abstract {
    text-align: center;
    margin-top: 50px;
  }

  .abstract h2 {
    font-size: 26px;
    margin-bottom: 10px;
    color: #000;
  }

  .abstract p {
    font-size: 17px;
    line-height: 1.6;
    max-width: 900px;
    margin: 0 auto;
  }

    .protocol-table {
  width: 100%;
  border-collapse: collapse;
  margin-top: 30px;
  font-size: 16px;
}

.protocol-table td {
  padding: 12px 14px;
  vertical-align: top;
}

.protocol-table tr {
  border-bottom: 1px solid #ddd;
}

.protocol-table .step {
  width: 32%;
  font-weight: 600;
}

.protocol-table .description {
  width: 68%;
}

.protocol-table .phase td {
  background-color: #f5f5f5;
  font-weight: 600;
  text-align: left;
}
  </style>
</head>

<body>

  <div class="container">

    <h1>PREP-Eval Pre-registration and REporting Protocol for AI Evaluations</h1>

    <div class="authors">
      <a href="https://it.linkedin.com/in/maria-victoria-carro-2409821b6/en" target="_blank">Mar√≠a Victoria Carro</a><sup>1,2</sup>,
      <a href="https://ryanburnell.com" target="_blank">Ryan Burnell</a><sup>3</sup>,
      <a href="https://cmougan.eu" target="_blank">Carlos Mougan</a><sup>4</sup>
      <a href="https://ankareuel.com/research" target="_blank">Anka Reuel</a><sup>5</sup>
      <a href="https://schellaert.org" target="_blank">Wout Schellaert</a><sup>4</sup>
      <a href="https://www.olawalesalaudeen.com" target="_blank">Olawale Elijah Salaudeen</a><sup>6</sup>
      <a href="https://lexzhou.github.io" target="_blank">Lexin Zhou</a><sup>7</sup>
      <a href="https://www.prpaskov.com" target="_blank">Patricia Paskov</a><sup>8</sup>
      <a href="https://www.linkedin.com/in/tonycohn/" target="_blank">Anthony G Cohn</a><sup>9</sup>
      <a href="http://josephorallo.webs.upv.es" target="_blank">Jose Hernandez-Orallo</a><sup>10,11</sup>
    </div>

    <div class="affiliations">
      <span class="affiliation"><sup>1</sup>Universit√† degli Studi di Genova, Italy</span>
      <span class="affiliation"><sup>2</sup>FAIR, IALAB UBA, University of Buenos Aires, Argentina</span>
      <span class="affiliation"><sup>3</sup>The Alan Turing Institute, United Kingdom</span>
      <span class="affiliation"><sup>4</sup>AI Office - European Commission, European Union</span>
      <span class="affiliation"><sup>5</sup>Stanford University, United States</span>
      <span class="affiliation"><sup>6</sup>Massachusetts Institute of Technology, United States</span>
      <span class="affiliation"><sup>7</sup>Princeton University, United States</span>
      <span class="affiliation"><sup>8</sup>Oxford Martin AI Governance Initiative, United Kingdom</span>
      <span class="affiliation"><sup>9</sup>University of Leeds, United Kingdom</span>
      <span class="affiliation"><sup>10</sup>Cambridge University, United Kingdom</span>
      <span class="affiliation"><sup>11</sup>Universitat Polit√®cnica de Val√®ncia, Spain</span>
    </div>

    <div class="buttons">
      <a class="button" href="mi_paper.pdf" target="_blank">üìÑ Paper</a>
    </div>

    <div class="section abstract">
  <h2>Abstract</h2>
  <p>
       Evaluation is an integral part of the development cycle of any AI system. As AI grows more sophisticated and general, evaluations are becoming increasingly complex and broad in scope, requiring larger multidisciplinary teams, longer timescales and more elaborate evaluation tools and techniques. Moreover, the opportunity to deploy these general-purpose AI systems across various commercial and public-sector contexts and the potential risks associated with these deployments has created a burgeoning need for non-expert groups to evaluate the suitability and safety of these models for use in different contexts. Surprisingly, though, despite the growing focus on evaluations, there is no established protocol or methodology for conducting AI evaluations. Here we aim to address this gap by presenting the ‚ÄúPre-registration and REporting Protocol for AI Evaluations‚Äù (PREP-Eval), a step-by-step guide for planning and conducting AI evaluations ‚Äã‚Äãthat complements existing transparency tools such as model cards and evaluation factsheets. We draw on insights from analogous practices in fields such as software testing, data mining, and psychology, and incorporate a pre-registration requirement that facilitates the documentation and justification of deviations from the original plan, helping to identify questionable research practices such as selective reporting. Our protocol is designed to support a wide range of stakeholders, including third-party evaluators, oversight bodies, and newcomers to the field, but it is particularly valuable for small and medium-sized research or industry teams that are developing new AI tools or integrating existing models into novel applications and may lack established evaluation pipelines. We demonstrate the application of PREP-Eval across six diverse use cases and anticipate that PREP-Eval will be further consolidated and improved through iterative feedback and collaboration with the broad AI community.
      </p>
    </div>

    <div class="section">
  <h2>PREP-Eval Protocol</h2>

  <table class="protocol-table">
    <tr class="phase">
      <td colspan="2"><strong>Phase 1: Goals and Objectives</strong></td>
    </tr>

    <tr>
      <td class="step">1.1 Determine project purpose</td>
      <td class="description">
        Describe the relevant background to the evaluation project, including the terminology,
        project goals, and success criteria.
      </td>
    </tr>

    <tr>
      <td class="step">1.2 Determine technical objectives</td>
      <td class="description">
        Identify and justify the targets of the evaluation, e.g., an AI system or a new evaluation
        method, and describe the success criteria in terms of metrics and uncertainty.
      </td>
    </tr>

    <tr>
      <td class="step">1.3 Situation assessment</td>
      <td class="description">
        Develop an inventory of resources, identify requirements and constraints, anticipate risks
        and contingencies, and assess current understanding of the evaluation targets.
      </td>
    </tr>

    <tr class="phase">
      <td colspan="2"><strong>Phase 2: Evaluation Design</strong></td>
    </tr>

    <tr>
      <td class="step">2.1 Identify potential evaluation methods</td>
      <td class="description">
        Review current evaluation methods, assess maturity and adoption, and monitor emerging
        approaches such as red teaming or human evaluations.
      </td>
    </tr>

    <tr>
      <td class="step">2.2 Selection of evaluation methods</td>
      <td class="description">
        Select an evaluation method and rigorously justify your choice. If no suitable methods
        exist, design or build new ones.
      </td>
    </tr>

    <tr>
      <td class="step">2.3 Analysis specification</td>
      <td class="description">
        Decide and justify how evaluation data will be analysed and what estimators will be
        produced, including metrics and error analysis.
      </td>
    </tr>
  </table>
</div>


  </div>

</body>
</html>
